{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8c2d42e-bc38-4849-9395-74a926030732",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "pTime=0\n",
    "\n",
    "mpFaceDetection=mp.solutions.face_detection\n",
    "mpDraw=mp.solutions.drawing_utils\n",
    "faceDetection=mpFaceDetection.FaceDetection()\n",
    "\"\"\"0 label_id: 0\n",
    "score: 0.9289083480834961\n",
    "location_data {\n",
    "  format: RELATIVE_BOUNDING_BOX\n",
    "  relative_bounding_box {\n",
    "    xmin: 0.3645336329936981\n",
    "    ymin: 0.39811718463897705\n",
    "    width: 0.30201444029808044\n",
    "    height: 0.402662456035614\n",
    "  }\n",
    "  relative_keypoints {\n",
    "    x: 0.4466734826564789\n",
    "    y: 0.49828624725341797\n",
    "  }\n",
    "  relative_keypoints {\n",
    "    x: 0.581633448600769\n",
    "    y: 0.48816245794296265                 this is the output format we get in face detection\n",
    "  }\n",
    "  relative_keypoints {\n",
    "    x: 0.5194463133811951\n",
    "    y: 0.573596715927124\n",
    "  }\n",
    "  relative_keypoints {\n",
    "    x: 0.5217621326446533\n",
    "    y: 0.6700312495231628\n",
    "  }\n",
    "  relative_keypoints {\n",
    "    x: 0.37251025438308716\n",
    "    y: 0.5656525492668152\n",
    "  }\n",
    "  relative_keypoints {\n",
    "    x: 0.6544674634933472\n",
    "    y: 0.546435534954071\n",
    "  }\n",
    "}\"\"\"\n",
    "\n",
    "while True:\n",
    "    success,img=cap.read()\n",
    "    cv2.resize(img,(1000,600))\n",
    "    if not success:\n",
    "        break\n",
    "    \n",
    "    imgRGB=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    result=faceDetection.process(imgRGB)\n",
    "\n",
    "    if result.detections:\n",
    "        for id,detection in enumerate(result.detections):\n",
    "            #mpDraw.draw_detection(img,detection)   draw points in video\n",
    "            #print(detection.location_data.relative_bounding_box) \n",
    "            \"\"\"                            _    \n",
    "               xmin: 0.41307950019836426    | location of pixel\n",
    "               ymin: 0.45183485746383667   _|\n",
    "               width: 0.3043389916419983               Date we get in printing detection.location_data.relative_bounding_box\n",
    "               height: 0.4057551622390747\"\"\"\n",
    "            \n",
    "            bboxC=detection.location_data.relative_bounding_box\n",
    "            ih,iw,ic =img.shape\n",
    "            bbox=int(bboxC.xmin*iw),int(bboxC.ymin*ih),\\\n",
    "            int(bboxC.width*iw),int(bboxC.height*ih)\n",
    "            cv2.rectangle(img,bbox,(255,34,25),2)\n",
    "            \n",
    "    \n",
    "    cTime=time.time()\n",
    "    fps=1/(cTime-pTime)   #its calculate the fps of track the hand \n",
    "    pTime=cTime\n",
    "    # its put text in img (img,fps,position,font,scale,color,thickness)\n",
    "    cv2.putText(img,str(int(fps)),(10,70),cv2.FONT_HERSHEY_PLAIN,3,(255,45,255),2)\n",
    "    cv2.imshow(\"you\",img)\n",
    "    if cv2.waitKey(1) & 0xff==ord(\"q\"):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f455a5-7b6b-47e5-8b83-f97d2eb9fb62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
