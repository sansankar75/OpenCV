{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e0d0a53-238f-4b16-83bb-11102fc9364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "#cap=cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)  # Use DirectShow\n",
    "\n",
    "\"\"\"wCam,hCam=1280,720\n",
    "cap.set(3,wCam)   #  -> its set the width and width seting id is 3 so we use 3      it not work in my laptop because my laptop fixed in Default Resolution: 640.0 x 480.0\n",
    "cap.set(4,hCam)\"\"\"   #  -> its set the height and 4 is this id \n",
    "pTime=0\n",
    "\n",
    "while True:\n",
    "    success,img=cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    cTime=time.time()\n",
    "    fps=1/(cTime-pTime)\n",
    "    pTime=cTime\n",
    "\n",
    "    cv2.putText(img,f'fps:{int(fps)}',(40,70),cv2.FONT_HERSHEY_COMPLEX,1,(15,78,244),3)\n",
    "    cv2.imshow(\"img of you:\",img)\n",
    "    if cv2.waitKey(1) & 0xff ==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf35d8f9-fc6a-4a58-a46f-09721833300c",
   "metadata": {},
   "source": [
    "if cv2.waitKey(1) and 0xff ==ord('q'):\n",
    "        break\n",
    "cv2.waitKey(1) wait for 1 milesecond \n",
    "in above code waitKey() wait for exact key we give (\"q\") from keybord , when key is pressed cv2.waitKey(1) its return 32 bit binary number (00000000 00000000 00000001 01110001  ) with ascii value like this then 0Xff is  hexa decimal number of (11111111) , we need only last 8 bit in 32 bit binary to system done bitwise and operation between 32 bit value and 8 bit hexadecimal ,after that we get 8 bit binary this is use to compare in the range of 0 to 255 ascii code ,In last ord('q') function return the ascii for 'q' alphabet (1) by doing bitwise & operation , so now 113 == 113"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d0b319-cfae-4591-9da9-8458db9467eb",
   "metadata": {},
   "source": [
    "cap.release()   -> its release the camara used by program \n",
    "cv2.destroyAllWindows() -> its close all the window created by cv2.imshow() function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80653150-9790-4655-b9dd-cd6376b8c5c7",
   "metadata": {},
   "source": [
    "Common cap.set() Properties\n",
    "\n",
    "Property ID  \tNamed Constant\t              Description\n",
    "3\t            cv2.CAP_PROP_FRAME_WIDTH\t  Frame width\n",
    "4\t            cv2.CAP_PROP_FRAME_HEIGHT\t  Frame height                     -> this is id for set()\n",
    "5\t            cv2.CAP_PROP_FPS\t          Frames per second\n",
    "10\t            cv2.CAP_PROP_BRIGHTNESS\t      Brightness level\n",
    "11\t            cv2.CAP_PROP_CONTRAST\t      Contrast level\n",
    "12\t            cv2.CAP_PROP_SATURATION\t      Saturation level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "921dc653-9863-421c-9e21-5253634e48ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "#system volumn buttom rise\n",
    "from ctypes import cast,POINTER                   #-> these are the needed packages\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities,IAudioEndpointVolume\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "mpHands=mp.solutions.hands  #fomality for use mediapipe\n",
    "hands=mpHands.Hands()\n",
    "mpDraw=mp.solutions.drawing_utils  # to draw the hands \n",
    "pTime=0\n",
    "cTime=0   #for calculate the fps \n",
    "\n",
    "devices=AudioUtilities.GetSpeakers()\n",
    "interface=devices.Activate(\n",
    "IAudioEndpointVolume._iid_,CLSCTX_ALL,None)\n",
    "volume=cast(interface,POINTER(IAudioEndpointVolume))\n",
    "#volume.GetMute()\n",
    "#volume.GetMasterVolumeLevel()\n",
    "volume_range=volume.GetVolumeRange()    # it we print this we get the value like this (-65.25, 0.0, 0.03125)  -65.25 is the minimum audio range and 0.0 is the maximum audio range \n",
    "\n",
    "minvol=volume_range[0]\n",
    "maxvol=volume_range[1]\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    \n",
    "    re,img=cap.read()   #its provide to things one is image and another one is opencv is able to access the camara\n",
    "    if not re:\n",
    "        break\n",
    "\n",
    "    imgRGB=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)   #this mediapipe only accept the rgb images so i convert into to need format\n",
    "    results=hands.process(imgRGB)  #i call the process method to process the hand\n",
    "    #print(results.multi_hand_landmarks)  #its show the process of detecting in landmarks (x,y,z values) the hand when we place your hand infront of camara\n",
    "    \n",
    "    #i only process the hand in camara\n",
    "    \"\"\"landmark {\n",
    "  x: 0.18886181712150574\n",
    "  y: 0.5954201817512512\n",
    "  z: -0.07697761058807373      this is a location of hand in img, In normal image we have 200x500 pixeland each pixel define as 2,45 like this  but we have pixel value in float so we need to change it \"\"\"\n",
    "    landmarks={}\n",
    "    if results.multi_hand_landmarks:\n",
    "        for handlms in results.multi_hand_landmarks:\n",
    "            #print(handlms)\n",
    "            for id , lm in enumerate(handlms.landmark):  #id return the id of landmark , id start form 0 to 20 , every id number is joins in hand refer hand landmarks in image in this file folder\n",
    "                h,w,c=img.shape\n",
    "                cx,cy=int(lm.x*w),int(lm.y*h)\n",
    "                landmarks[id]=(cx,cy) \n",
    "                \n",
    "                cv2.circle(img,(cx,cy),7,(255,56,34),cv2.FILLED)     #to circle in  all joints in img\n",
    "            \n",
    "                if id in [4,8]:\n",
    "                     cv2.circle(img,(cx,cy),10,(234,243,255),cv2.FILLED)     #assign different value in 4 and 8 th point\n",
    "                # to draw line between two points (4 and 8)\n",
    "                if 4 in landmarks and 8 in landmarks:                        \n",
    "                    cv2.line(img,landmarks[4],landmarks[8],(4,78,96),3)  \n",
    "                    center=(((landmarks[4][0]+landmarks[8][0])//2),(((landmarks[4][1]+landmarks[8][1])//2)))  #to find the center point between two point(4 and 8)\n",
    "                    cv2.circle(img,center,10,(245,78,36),cv2.FILLED)\n",
    "                    system_volume_set=abs(landmarks[4][0]-landmarks[8][0])   # min value is 15 and max value is 253\n",
    "                    \n",
    "                    vol=np.interp(system_volume_set,[15,230],[minvol,maxvol])\n",
    "                    volume.SetMasterVolumeLevel(vol,None)  #it set a system volume\n",
    "                  \n",
    "                    if system_volume_set <50:\n",
    "                        cv2.circle(img,center,20,(39,241,86),cv2.FILLED)\n",
    "                    \n",
    "    \n",
    "                \n",
    "            mpDraw.draw_landmarks(img,handlms,mpHands.HAND_CONNECTIONS)   #its draw the join and connections between joins\n",
    "\n",
    "    cTime=time.time()\n",
    "    fps=1/(cTime-pTime)   #its calculate the fps of track the hand \n",
    "    pTime=cTime\n",
    "    \n",
    "    # its put text in img (img,fps,position,font,scale,color,thickness)\n",
    "    cv2.putText(img,str(int(fps)),(10,70),cv2.FONT_HERSHEY_PLAIN,3,(255,4,255),2)\n",
    "\n",
    "    \n",
    "    cv2.imshow(\"video smile please\",img)\n",
    "    if cv2.waitKey(1) & 0xFF==ord(\"q\"):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc210809-d487-4fb0-8a8b-b4554dab6cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
